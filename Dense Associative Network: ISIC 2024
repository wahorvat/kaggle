{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":63056,"databundleVersionId":9094797,"sourceType":"competition"}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport pandas.api.types\nimport jax\nimport jax.numpy as jnp\nfrom jax import jit\nfrom flax import linen as nn\n\nimport h5py\nimport itertools\nfrom PIL import Image\nfrom pathlib import Path\nimport time\n\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\n\nfrom scipy.stats import zscore\nfrom numpy import nanmean, nanstd\nnp.seterr(invalid='ignore')\n\nimport copy\nimport os\nimport io","metadata":{"execution":{"iopub.status.busy":"2024-09-09T16:26:17.693171Z","iopub.execute_input":"2024-09-09T16:26:17.694144Z","iopub.status.idle":"2024-09-09T16:26:17.700939Z","shell.execute_reply.started":"2024-09-09T16:26:17.694098Z","shell.execute_reply":"2024-09-09T16:26:17.699823Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"file_path_train_meta = '/kaggle/input/isic-2024-challenge/train-metadata.csv'\nfile_path_test_meta = '/kaggle/input/isic-2024-challenge/test-metadata.csv'\n\ndf_train = pd.read_csv(file_path_train_meta)\ndf_test = pd.read_csv(file_path_test_meta)","metadata":{"execution":{"iopub.status.busy":"2024-09-09T16:17:55.590422Z","iopub.execute_input":"2024-09-09T16:17:55.591311Z","iopub.status.idle":"2024-09-09T16:18:03.829618Z","shell.execute_reply.started":"2024-09-09T16:17:55.591269Z","shell.execute_reply":"2024-09-09T16:18:03.828610Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_36/741273269.py:4: DtypeWarning: Columns (51,52) have mixed types. Specify dtype option on import or set low_memory=False.\n  df_train = pd.read_csv(file_path_train_meta)\n","output_type":"stream"}]},{"cell_type":"code","source":"train_targets = df_train['target'].to_numpy()\n\nunique, counts = np.unique(train_targets, return_counts=True)\ncount_dict = dict(zip(unique, counts))\nprint(count_dict)","metadata":{"execution":{"iopub.status.busy":"2024-09-09T16:18:20.790341Z","iopub.execute_input":"2024-09-09T16:18:20.790750Z","iopub.status.idle":"2024-09-09T16:18:20.810397Z","shell.execute_reply.started":"2024-09-09T16:18:20.790712Z","shell.execute_reply":"2024-09-09T16:18:20.809595Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"{0: 400666, 1: 393}\n","output_type":"stream"}]},{"cell_type":"code","source":"def filter_columns(df: pd.DataFrame, keep_columns: list) -> pd.DataFrame:\n    \"\"\"\n    Remove columns from a DataFrame that are not in the specified list.\n    \n    :param df: Input DataFrame\n    :param keep_columns: List of column names to keep\n    :return: DataFrame with only the specified columns\n    \"\"\"\n    # Find the intersection of existing columns and the keep_columns list\n    columns_to_keep = [col for col in keep_columns if col in df.columns]\n    \n    # Return the DataFrame with only the specified columns\n    return df[columns_to_keep]\n\ntest_cols = df_test.columns\nprint(test_cols)\n\nfiltered_df_train = filter_columns(df_train, test_cols)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-09T16:18:22.715918Z","iopub.execute_input":"2024-09-09T16:18:22.716617Z","iopub.status.idle":"2024-09-09T16:18:22.781845Z","shell.execute_reply.started":"2024-09-09T16:18:22.716575Z","shell.execute_reply":"2024-09-09T16:18:22.780903Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Index(['isic_id', 'patient_id', 'age_approx', 'sex', 'anatom_site_general',\n       'clin_size_long_diam_mm', 'image_type', 'tbp_tile_type', 'tbp_lv_A',\n       'tbp_lv_Aext', 'tbp_lv_B', 'tbp_lv_Bext', 'tbp_lv_C', 'tbp_lv_Cext',\n       'tbp_lv_H', 'tbp_lv_Hext', 'tbp_lv_L', 'tbp_lv_Lext', 'tbp_lv_areaMM2',\n       'tbp_lv_area_perim_ratio', 'tbp_lv_color_std_mean', 'tbp_lv_deltaA',\n       'tbp_lv_deltaB', 'tbp_lv_deltaL', 'tbp_lv_deltaLB',\n       'tbp_lv_deltaLBnorm', 'tbp_lv_eccentricity', 'tbp_lv_location',\n       'tbp_lv_location_simple', 'tbp_lv_minorAxisMM',\n       'tbp_lv_nevi_confidence', 'tbp_lv_norm_border', 'tbp_lv_norm_color',\n       'tbp_lv_perimeterMM', 'tbp_lv_radial_color_std_max', 'tbp_lv_stdL',\n       'tbp_lv_stdLExt', 'tbp_lv_symm_2axis', 'tbp_lv_symm_2axis_angle',\n       'tbp_lv_x', 'tbp_lv_y', 'tbp_lv_z', 'attribution', 'copyright_license'],\n      dtype='object')\n","output_type":"stream"}]},{"cell_type":"code","source":"cat_cols = ['patient_id','age_approx', 'sex', 'anatom_site_general', \n            'image_type', 'tbp_tile_type', 'tbp_lv_location', \n            'tbp_lv_location_simple', 'attribution', 'copyright_license']","metadata":{"execution":{"iopub.status.busy":"2024-09-09T16:18:25.257284Z","iopub.execute_input":"2024-09-09T16:18:25.258163Z","iopub.status.idle":"2024-09-09T16:18:25.262278Z","shell.execute_reply.started":"2024-09-09T16:18:25.258124Z","shell.execute_reply":"2024-09-09T16:18:25.261403Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"filtered_df_train = filtered_df_train.copy()\n\n# Encode categories\ncategory_encoder = OrdinalEncoder(\n    categories='auto',\n    dtype=int,\n    handle_unknown='use_encoded_value',\n    unknown_value=-2,\n    encoded_missing_value=-1,\n)\n\n# Transform training data\nX_cat_train = category_encoder.fit_transform(filtered_df_train[cat_cols])\nfor c, cat_col in enumerate(cat_cols):\n    filtered_df_train.loc[:, cat_col] = X_cat_train[:, c]\n\n# Transform test data\nX_cat_test = category_encoder.transform(df_test[cat_cols])\nfor c, cat_col in enumerate(cat_cols):\n    df_test.loc[:, cat_col] = X_cat_test[:, c]\n\nprint(\"Encoding complete.\")","metadata":{"execution":{"iopub.status.busy":"2024-09-09T16:18:31.939665Z","iopub.execute_input":"2024-09-09T16:18:31.940047Z","iopub.status.idle":"2024-09-09T16:18:33.418746Z","shell.execute_reply.started":"2024-09-09T16:18:31.940010Z","shell.execute_reply":"2024-09-09T16:18:33.416726Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Encoding complete.\n","output_type":"stream"}]},{"cell_type":"code","source":"def normalize_dataframe_columns(df, method='minmax', exclude_columns=None):\n    \"\"\"\n    Normalize each column of a DataFrame independently.\n    \n    :param df: Input DataFrame\n    :param method: 'minmax' for Min-Max scaling, 'standard' for Standardization\n    :param exclude_columns: List of column names to exclude from normalization\n    :return: Normalized DataFrame\n    \"\"\"\n    # Create a copy of the DataFrame to avoid modifying the original\n    df_normalized = df.copy()\n    \n    if exclude_columns is None:\n        exclude_columns = []\n    \n    # Select numeric columns, excluding specified columns\n    numeric_columns = df.select_dtypes(include=[np.number]).columns\n    columns_to_normalize = [col for col in numeric_columns if col not in exclude_columns]\n    \n    if method == 'minmax':\n        scaler = MinMaxScaler()\n    elif method == 'standard':\n        scaler = StandardScaler()\n    else:\n        raise ValueError(\"Method must be 'minmax' or 'standard'\")\n    \n    # Normalize each column independently\n    for column in columns_to_normalize:\n        df_normalized[column] = scaler.fit_transform(df_normalized[[column]])\n    \n    return df_normalized\n\n\n# Normalize using Standard scaling\ndf_train_minmax = normalize_dataframe_columns(filtered_df_train, method='standard')\ndf_test_minmax = normalize_dataframe_columns(df_test, method='standard')\n","metadata":{"execution":{"iopub.status.busy":"2024-09-09T16:18:36.740523Z","iopub.execute_input":"2024-09-09T16:18:36.740921Z","iopub.status.idle":"2024-09-09T16:18:37.161207Z","shell.execute_reply.started":"2024-09-09T16:18:36.740884Z","shell.execute_reply":"2024-09-09T16:18:37.160330Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Convert df row data to row elements in a jax array of type float\nnumeric_train_data_jax = jnp.array(df_train_minmax.iloc[0:, 1:].to_numpy(dtype=float))\nnumeric_test_data_jax = jnp.array(df_test_minmax.iloc[0:, 1:].to_numpy(dtype=float))","metadata":{"execution":{"iopub.status.busy":"2024-09-09T16:18:41.749376Z","iopub.execute_input":"2024-09-09T16:18:41.750427Z","iopub.status.idle":"2024-09-09T16:18:43.497866Z","shell.execute_reply.started":"2024-09-09T16:18:41.750353Z","shell.execute_reply":"2024-09-09T16:18:43.497035Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# Combining image and tabular data","metadata":{}},{"cell_type":"code","source":"file_path_train = '/kaggle/input/isic-2024-challenge/train-image.hdf5'\nfile_path_test = '/kaggle/input/isic-2024-challenge/test-image.hdf5'\n\ndef hdf5_keys(image_dir):\n    with h5py.File(image_dir, 'r') as f:\n        dataset_names = list(f.keys())\n    return dataset_names\n\ntrain_keys = hdf5_keys(file_path_train)\ntest_keys = hdf5_keys(file_path_test)","metadata":{"execution":{"iopub.status.busy":"2024-09-09T16:18:46.369739Z","iopub.execute_input":"2024-09-09T16:18:46.370627Z","iopub.status.idle":"2024-09-09T16:19:50.531790Z","shell.execute_reply.started":"2024-09-09T16:18:46.370581Z","shell.execute_reply":"2024-09-09T16:19:50.530728Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# # Load and preprocess images\n\ndef load_images(image_dir, keys, numeric_df, batch, num_images=5000):\n    with h5py.File(image_dir, 'r') as f:\n        images = []\n        for idx, name in enumerate(keys[batch*num_images:(batch*num_images)+num_images]):\n            img = f[name][()]\n            img = Image.open(io.BytesIO(img))\n            img_resized = img.resize((128, 128))\n            img_array = jnp.asarray(img_resized).flatten() \n            df_row = numeric_df[batch*num_images + idx]\n            combined_array = jnp.concatenate([img_array, df_row])\n            images.append(combined_array)\n        return jnp.stack(images)\n\n\n# train_img_stack = load_images(file_path_train, train_keys, numeric_train_data_jax, 0)\n# test_img_stack = load_images(file_path_test, test_keys, numeric_test_data_jax, 0, num_images=3)","metadata":{"execution":{"iopub.status.busy":"2024-09-09T16:19:55.021178Z","iopub.execute_input":"2024-09-09T16:19:55.021919Z","iopub.status.idle":"2024-09-09T16:19:55.028886Z","shell.execute_reply.started":"2024-09-09T16:19:55.021876Z","shell.execute_reply":"2024-09-09T16:19:55.027877Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# class MultiClassImageEnergyF(eqx.Module):\n#     W: jax.Array\n#     labelW: jax.Array\n#     beta: float\n    \n#     def __init__(self, Winit: jax.Array, labelW_init: jax.Array, beta_init=1.):\n#         self.W = jnp.array(Winit)\n#         self.labelW = jnp.array(labelW_init)\n#         self.beta = beta_init\n        \n#     def __call__(self, x, labels=None):\n#         \"\"\"Compute the energy of the memories given a particular label\"\"\"\n#         assert len(x.shape) < 2, \"No batch dimension\"\n\n#         sim = -jnp.sum(jnp.power(self.W - x, 2), -1)    \n#         energy = -jax.nn.logsumexp(self.beta * sim[:, None] + self.labelW.T, axis=1)\n        \n#         return energy\n    \n#     def update(self, new_W: jax.Array, new_labelW: jax.Array):\n#         \"\"\"Update the model with new data\"\"\"\n#         return MultiClassImageEnergyF(new_W, new_labelW, self.beta)\n\n    \n# def find_most_similar_image(model, test_images):\n#     # Vectorize the model call over the batch dimension\n#     batched_model = jax.vmap(model)\n    \n#     # Compute energies for all test images in parallel\n#     energies = batched_model(test_images)\n    \n#     # Find the most similar index for each test image\n#     most_similar_idxs = jnp.argmin(energies, axis=1)\n    \n#     return most_similar_idxs\n\n\n# # Ensure the function runs on GPU\n# @jax.jit\n# def jitted_find_most_similar_image(model, test_images):\n#     return find_most_similar_image(model, test_images)\n\n\n# No equinox model\ndef create_model(Winit: jax.Array, labelW_init: jax.Array, beta_init=1.):\n    return {\n        'W': jnp.array(Winit),\n        'labelW': jnp.array(labelW_init),\n        'beta': beta_init\n    }\n\ndef model_call(params, x):\n    \"\"\"Compute the energy of the memories given a particular label\"\"\"\n    assert len(x.shape) < 2, \"No batch dimension\"\n    sim = -jnp.sum(jnp.power(params['W'] - x, 2), -1)    \n    energy = -jax.nn.logsumexp(params['beta'] * sim[:, None] + params['labelW'].T, axis=1)\n    return energy\n\ndef update_model(params, new_W: jax.Array, new_labelW: jax.Array):\n    \"\"\"Update the model with new data\"\"\"\n    return {\n        'W': new_W,\n        'labelW': new_labelW,\n        'beta': params['beta']\n    }\n\ndef find_most_similar_image(params, test_images):\n    # Vectorize the model call over the batch dimension\n    batched_model = jax.vmap(lambda x: model_call(params, x))\n    \n    # Compute energies for all test images in parallel\n    energies = batched_model(test_images)\n    \n    # Find the most similar index for each test image\n    most_similar_idxs = jnp.argmin(energies, axis=1)\n    \n    return most_similar_idxs\n\n# Ensure the function runs on GPU\n@jax.jit\ndef jitted_find_most_similar_image(params, test_images):\n    return find_most_similar_image(params, test_images)","metadata":{"execution":{"iopub.status.busy":"2024-09-09T16:26:26.442050Z","iopub.execute_input":"2024-09-09T16:26:26.443007Z","iopub.status.idle":"2024-09-09T16:26:26.460888Z","shell.execute_reply.started":"2024-09-09T16:26:26.442965Z","shell.execute_reply":"2024-09-09T16:26:26.459793Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"num_train = len(train_keys)\nnum_test = len(test_keys)\n\nbatch_size = 5000\ntotal_train_batches = (num_train + batch_size - 1) // batch_size\ntotal_test_batches = (num_test + batch_size - 1) // batch_size\nprint(total_train_batches)","metadata":{"execution":{"iopub.status.busy":"2024-09-09T16:22:18.619750Z","iopub.execute_input":"2024-09-09T16:22:18.620141Z","iopub.status.idle":"2024-09-09T16:22:18.626107Z","shell.execute_reply.started":"2024-09-09T16:22:18.620105Z","shell.execute_reply":"2024-09-09T16:22:18.625094Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"5\n","output_type":"stream"}]},{"cell_type":"code","source":"# Initialize model\nnum_classes = 20000\ntrain_img_stack = load_images(file_path_train, train_keys, numeric_train_data_jax, batch=0)\nprint(train_img_stack.shape)\n\nW_init = train_img_stack[0:batch_size]\nlabelW_init = jax.nn.one_hot(jnp.arange(batch_size), num_classes=batch_size)\nmodel_params = create_model(W_init, labelW_init, beta_init=1.)\n\n# print(\"Model W shape:\", model.W.shape)\n# print(\"Model labelW shape:\", model.labelW.shape)\n# print(\"Model beta:\", model.beta)\n\n\n# Training loop on training images and numeric data, loss and epochs are irrelevant to model training\nfor train_batch in range(1, total_train_batches):\n    start_time = time.time()\n    train_img_stack = load_images(file_path_train, train_keys, numeric_train_data_jax, train_batch)\n    W = train_img_stack\n    Nsamples = len(W)\n    \n    labels = jnp.arange(Nsamples)\n    labelW = jax.nn.one_hot(jnp.arange(Nsamples), num_classes=Nsamples)\n\n    # Update the existing model with new data\n    model_params = update_model(model_params, W, labelW)\n    \n    end_time = time.time()\n    print(f'Time for batch {train_batch} of {total_train_batches} is {end_time - start_time}')\n    # print(\"W shape:\", model.W.shape, \"labelW shape:\", model.labelW.shape, \"beta:\", model.beta)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-09T16:22:24.335330Z","iopub.execute_input":"2024-09-09T16:22:24.335760Z","iopub.status.idle":"2024-09-09T16:23:28.386701Z","shell.execute_reply.started":"2024-09-09T16:22:24.335722Z","shell.execute_reply":"2024-09-09T16:23:28.385357Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"(5000, 49195)\nModel W shape: (5000, 49195)\nModel labelW shape: (5000, 5000)\nModel beta: 1.0\n(5000, 49195)\nTime for batch 1 of 5 is 12.875877618789673\nW shape: (5000, 49195) labelW shape: (5000, 5000) beta: 1.0\n(5000, 49195)\nTime for batch 2 of 5 is 12.693942308425903\nW shape: (5000, 49195) labelW shape: (5000, 5000) beta: 1.0\n(5000, 49195)\nTime for batch 3 of 5 is 12.742012023925781\nW shape: (5000, 49195) labelW shape: (5000, 5000) beta: 1.0\n(5000, 49195)\nTime for batch 4 of 5 is 12.961392641067505\nW shape: (5000, 49195) labelW shape: (5000, 5000) beta: 1.0\n","output_type":"stream"}]},{"cell_type":"code","source":"# print(\"Model W shape:\", model.W.shape)\n# print(\"Model labelW shape:\", model.labelW.shape)\n# print(\"Model beta:\", model.beta)","metadata":{"execution":{"iopub.status.busy":"2024-09-09T16:24:04.166600Z","iopub.execute_input":"2024-09-09T16:24:04.167599Z","iopub.status.idle":"2024-09-09T16:24:04.173022Z","shell.execute_reply.started":"2024-09-09T16:24:04.167555Z","shell.execute_reply":"2024-09-09T16:24:04.172009Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Model W shape: (5000, 49195)\nModel labelW shape: (5000, 5000)\nModel beta: 1.0\n","output_type":"stream"}]},{"cell_type":"code","source":"preds = np.zeros(len(test_keys))\n\nfor test_batch in range(total_test_batches):\n    test_img_stack = load_images(file_path_test, test_keys, numeric_test_data_jax, test_batch)\n    most_similar_idx = jitted_find_most_similar_image(model_params, test_img_stack)\n    for pred_idx, idx in enumerate(most_similar_idx):\n        preds[(test_batch*batch_size)+pred_idx] = train_targets[idx]\n","metadata":{"execution":{"iopub.status.busy":"2024-09-09T16:24:38.505578Z","iopub.execute_input":"2024-09-09T16:24:38.506107Z","iopub.status.idle":"2024-09-09T16:24:38.542461Z","shell.execute_reply.started":"2024-09-09T16:24:38.506056Z","shell.execute_reply":"2024-09-09T16:24:38.541463Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# display_images((np.array(test_img_stack[0][:49152]).reshape(128, 128, 3)).astype(np.uint8), (np.array(train_img_stack[most_similar_idx][:49152]).reshape(128, 128, 3)).astype(np.uint8), most_similar_idx)","metadata":{"execution":{"iopub.status.busy":"2024-09-09T15:43:46.169345Z","iopub.execute_input":"2024-09-09T15:43:46.169933Z","iopub.status.idle":"2024-09-09T15:43:46.176542Z","shell.execute_reply.started":"2024-09-09T15:43:46.169882Z","shell.execute_reply":"2024-09-09T15:43:46.174990Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"code","source":"# import matplotlib.pyplot as plt\n\n# def plot_energy_scatter(energies, title=\"Energy Scatter Plot\", x_label=\"Data Point\", y_label=\"Energy\"):\n#     \"\"\"\n#     Plot a scatter plot of energies against the number of data points.\n    \n#     Parameters:\n#     energies (list): List of energy values to plot\n#     title (str): Title of the plot\n#     x_label (str): Label for the x-axis\n#     y_label (str): Label for the y-axis\n#     \"\"\"\n#     # Generate x-axis values (1 to number of data points)\n#     x_values = range(1, len(energies) + 1)\n    \n#     # Create the scatter plot\n#     plt.figure(figsize=(10, 6))\n#     plt.scatter(x_values, energies / 100, alpha=0.2)\n    \n#     # Set title and labels\n#     plt.title(title)\n#     plt.xlabel(x_label)\n#     plt.ylabel(y_label)\n    \n#     # Set y-axis limits\n#     plt.ylim(-200000, 300000)\n    \n#     # Add grid for better readability\n#     plt.grid(True, linestyle='--', alpha=0.7)\n    \n#     # Show the plot\n#     plt.show()\n\n# # Example usage\n# # Uncomment and modify these lines to test the function\n# # import numpy as np\n# # sample_energies = np.random.rand(100) * 10  # 100 random energy values between 0 and 10\n# # plot_energy_scatter(sample_energies, title=\"Sample Energy Distribution\")","metadata":{"execution":{"iopub.status.busy":"2024-09-09T01:19:03.173125Z","iopub.execute_input":"2024-09-09T01:19:03.173645Z","iopub.status.idle":"2024-09-09T01:19:03.180617Z","shell.execute_reply.started":"2024-09-09T01:19:03.173594Z","shell.execute_reply":"2024-09-09T01:19:03.179391Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"#plot_energy_scatter(energies, title=\"Sample Energy Distribution\")","metadata":{"execution":{"iopub.status.busy":"2024-09-09T01:18:58.142307Z","iopub.execute_input":"2024-09-09T01:18:58.142847Z","iopub.status.idle":"2024-09-09T01:18:58.148172Z","shell.execute_reply.started":"2024-09-09T01:18:58.142798Z","shell.execute_reply":"2024-09-09T01:18:58.146704Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"df_sub = pd.read_csv(\"/kaggle/input/isic-2024-challenge/sample_submission.csv\")\ndf_sub[\"target\"] = preds\ndf_sub.to_csv(\"submission.csv\", index=False)\ndf_sub","metadata":{"execution":{"iopub.status.busy":"2024-09-09T16:24:10.850498Z","iopub.execute_input":"2024-09-09T16:24:10.850883Z","iopub.status.idle":"2024-09-09T16:24:10.873299Z","shell.execute_reply.started":"2024-09-09T16:24:10.850847Z","shell.execute_reply":"2024-09-09T16:24:10.872373Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"        isic_id  target\n0  ISIC_0015657     0.0\n1  ISIC_0015729     0.0\n2  ISIC_0015740     0.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>isic_id</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ISIC_0015657</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ISIC_0015729</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ISIC_0015740</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]}]}