{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":63056,"databundleVersionId":9094797,"sourceType":"competition"}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%pip install equinox\n%pip install einops\n\nimport numpy as np\nimport pandas as pd\nimport pandas.api.types\nimport jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\nimport equinox as eqx\nfrom einops import rearrange\n\nimport h5py\nimport itertools\nfrom PIL import Image\nfrom pathlib import Path\nimport time\n\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\n\nfrom scipy.stats import zscore\nfrom numpy import nanmean, nanstd\nnp.seterr(invalid='ignore')\n\nimport copy\nimport os\nimport io","metadata":{"execution":{"iopub.status.busy":"2024-09-06T22:42:35.983610Z","iopub.execute_input":"2024-09-06T22:42:35.983993Z","iopub.status.idle":"2024-09-06T22:43:06.961760Z","shell.execute_reply.started":"2024-09-06T22:42:35.983954Z","shell.execute_reply":"2024-09-06T22:43:06.960747Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting equinox\n  Downloading equinox-0.11.5-py3-none-any.whl.metadata (18 kB)\nRequirement already satisfied: jax!=0.4.27,>=0.4.13 in /opt/conda/lib/python3.10/site-packages (from equinox) (0.4.26)\nCollecting jaxtyping>=0.2.20 (from equinox)\n  Downloading jaxtyping-0.2.34-py3-none-any.whl.metadata (6.4 kB)\nRequirement already satisfied: typing-extensions>=4.5.0 in /opt/conda/lib/python3.10/site-packages (from equinox) (4.12.2)\nRequirement already satisfied: ml-dtypes>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from jax!=0.4.27,>=0.4.13->equinox) (0.3.2)\nRequirement already satisfied: numpy>=1.22 in /opt/conda/lib/python3.10/site-packages (from jax!=0.4.27,>=0.4.13->equinox) (1.26.4)\nRequirement already satisfied: opt-einsum in /opt/conda/lib/python3.10/site-packages (from jax!=0.4.27,>=0.4.13->equinox) (3.3.0)\nRequirement already satisfied: scipy>=1.9 in /opt/conda/lib/python3.10/site-packages (from jax!=0.4.27,>=0.4.13->equinox) (1.14.0)\nCollecting typeguard==2.13.3 (from jaxtyping>=0.2.20->equinox)\n  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\nDownloading equinox-0.11.5-py3-none-any.whl (177 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.3/177.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading jaxtyping-0.2.34-py3-none-any.whl (42 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading typeguard-2.13.3-py3-none-any.whl (17 kB)\nInstalling collected packages: typeguard, jaxtyping, equinox\n  Attempting uninstall: typeguard\n    Found existing installation: typeguard 4.3.0\n    Uninstalling typeguard-4.3.0:\n      Successfully uninstalled typeguard-4.3.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nydata-profiling 4.9.0 requires scipy<1.14,>=1.4.1, but you have scipy 1.14.0 which is incompatible.\nydata-profiling 4.9.0 requires typeguard<5,>=3, but you have typeguard 2.13.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed equinox-0.11.5 jaxtyping-0.2.34 typeguard-2.13.3\nNote: you may need to restart the kernel to use updated packages.\nCollecting einops\n  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\nDownloading einops-0.8.0-py3-none-any.whl (43 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: einops\nSuccessfully installed einops-0.8.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"file_path_train_meta = '/kaggle/input/isic-2024-challenge/train-metadata.csv'\nfile_path_test_meta = '/kaggle/input/isic-2024-challenge/test-metadata.csv'\n\ndf_train = pd.read_csv(file_path_train_meta)\ndf_test = pd.read_csv(file_path_test_meta)","metadata":{"execution":{"iopub.status.busy":"2024-09-06T22:43:29.725915Z","iopub.execute_input":"2024-09-06T22:43:29.726873Z","iopub.status.idle":"2024-09-06T22:43:36.964822Z","shell.execute_reply.started":"2024-09-06T22:43:29.726829Z","shell.execute_reply":"2024-09-06T22:43:36.963814Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_36/741273269.py:4: DtypeWarning: Columns (51,52) have mixed types. Specify dtype option on import or set low_memory=False.\n  df_train = pd.read_csv(file_path_train_meta)\n","output_type":"stream"}]},{"cell_type":"code","source":"def filter_columns(df: pd.DataFrame, keep_columns: list) -> pd.DataFrame:\n    \"\"\"\n    Remove columns from a DataFrame that are not in the specified list.\n    \n    :param df: Input DataFrame\n    :param keep_columns: List of column names to keep\n    :return: DataFrame with only the specified columns\n    \"\"\"\n    # Find the intersection of existing columns and the keep_columns list\n    columns_to_keep = [col for col in keep_columns if col in df.columns]\n    \n    # Return the DataFrame with only the specified columns\n    return df[columns_to_keep]\n\ntest_cols = df_test.columns#.difference({'age_approx'})\nprint(test_cols)\n\nfiltered_df_train = filter_columns(df_train, test_cols)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-06T22:43:39.306919Z","iopub.execute_input":"2024-09-06T22:43:39.307316Z","iopub.status.idle":"2024-09-06T22:43:39.378210Z","shell.execute_reply.started":"2024-09-06T22:43:39.307265Z","shell.execute_reply":"2024-09-06T22:43:39.376578Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Index(['isic_id', 'patient_id', 'age_approx', 'sex', 'anatom_site_general',\n       'clin_size_long_diam_mm', 'image_type', 'tbp_tile_type', 'tbp_lv_A',\n       'tbp_lv_Aext', 'tbp_lv_B', 'tbp_lv_Bext', 'tbp_lv_C', 'tbp_lv_Cext',\n       'tbp_lv_H', 'tbp_lv_Hext', 'tbp_lv_L', 'tbp_lv_Lext', 'tbp_lv_areaMM2',\n       'tbp_lv_area_perim_ratio', 'tbp_lv_color_std_mean', 'tbp_lv_deltaA',\n       'tbp_lv_deltaB', 'tbp_lv_deltaL', 'tbp_lv_deltaLB',\n       'tbp_lv_deltaLBnorm', 'tbp_lv_eccentricity', 'tbp_lv_location',\n       'tbp_lv_location_simple', 'tbp_lv_minorAxisMM',\n       'tbp_lv_nevi_confidence', 'tbp_lv_norm_border', 'tbp_lv_norm_color',\n       'tbp_lv_perimeterMM', 'tbp_lv_radial_color_std_max', 'tbp_lv_stdL',\n       'tbp_lv_stdLExt', 'tbp_lv_symm_2axis', 'tbp_lv_symm_2axis_angle',\n       'tbp_lv_x', 'tbp_lv_y', 'tbp_lv_z', 'attribution', 'copyright_license'],\n      dtype='object')\n","output_type":"stream"}]},{"cell_type":"code","source":"cat_cols = ['patient_id','age_approx', 'sex', 'anatom_site_general', \n            'image_type', 'tbp_tile_type', 'tbp_lv_location', \n            'tbp_lv_location_simple', 'attribution', 'copyright_license']\n#filtered_df_train.head()\n#filtered_df_train.isna().any()","metadata":{"execution":{"iopub.status.busy":"2024-09-06T22:43:42.064448Z","iopub.execute_input":"2024-09-06T22:43:42.065192Z","iopub.status.idle":"2024-09-06T22:43:42.448943Z","shell.execute_reply.started":"2024-09-06T22:43:42.065152Z","shell.execute_reply":"2024-09-06T22:43:42.448067Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"isic_id                        False\npatient_id                     False\nage_approx                      True\nsex                             True\nanatom_site_general             True\nclin_size_long_diam_mm         False\nimage_type                     False\ntbp_tile_type                  False\ntbp_lv_A                       False\ntbp_lv_Aext                    False\ntbp_lv_B                       False\ntbp_lv_Bext                    False\ntbp_lv_C                       False\ntbp_lv_Cext                    False\ntbp_lv_H                       False\ntbp_lv_Hext                    False\ntbp_lv_L                       False\ntbp_lv_Lext                    False\ntbp_lv_areaMM2                 False\ntbp_lv_area_perim_ratio        False\ntbp_lv_color_std_mean          False\ntbp_lv_deltaA                  False\ntbp_lv_deltaB                  False\ntbp_lv_deltaL                  False\ntbp_lv_deltaLB                 False\ntbp_lv_deltaLBnorm             False\ntbp_lv_eccentricity            False\ntbp_lv_location                False\ntbp_lv_location_simple         False\ntbp_lv_minorAxisMM             False\ntbp_lv_nevi_confidence         False\ntbp_lv_norm_border             False\ntbp_lv_norm_color              False\ntbp_lv_perimeterMM             False\ntbp_lv_radial_color_std_max    False\ntbp_lv_stdL                    False\ntbp_lv_stdLExt                 False\ntbp_lv_symm_2axis              False\ntbp_lv_symm_2axis_angle        False\ntbp_lv_x                       False\ntbp_lv_y                       False\ntbp_lv_z                       False\nattribution                    False\ncopyright_license              False\ndtype: bool"},"metadata":{}}]},{"cell_type":"code","source":"filtered_df_train = filtered_df_train.copy()\n\n# Encode categories\ncategory_encoder = OrdinalEncoder(\n    categories='auto',\n    dtype=int,\n    handle_unknown='use_encoded_value',\n    unknown_value=-2,\n    encoded_missing_value=-1,\n)\n\n# Transform training data\nX_cat_train = category_encoder.fit_transform(filtered_df_train[cat_cols])\nfor c, cat_col in enumerate(cat_cols):\n    filtered_df_train.loc[:, cat_col] = X_cat_train[:, c]\n\n# Transform test data\nX_cat_test = category_encoder.transform(df_test[cat_cols])\nfor c, cat_col in enumerate(cat_cols):\n    df_test.loc[:, cat_col] = X_cat_test[:, c]\n\nprint(\"Encoding complete.\")","metadata":{"execution":{"iopub.status.busy":"2024-09-06T22:43:45.358276Z","iopub.execute_input":"2024-09-06T22:43:45.358925Z","iopub.status.idle":"2024-09-06T22:43:46.731828Z","shell.execute_reply.started":"2024-09-06T22:43:45.358881Z","shell.execute_reply":"2024-09-06T22:43:46.730748Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Encoding complete.\n","output_type":"stream"}]},{"cell_type":"code","source":"def normalize_dataframe_columns(df, method='minmax', exclude_columns=None):\n    \"\"\"\n    Normalize each column of a DataFrame independently.\n    \n    :param df: Input DataFrame\n    :param method: 'minmax' for Min-Max scaling, 'standard' for Standardization\n    :param exclude_columns: List of column names to exclude from normalization\n    :return: Normalized DataFrame\n    \"\"\"\n    # Create a copy of the DataFrame to avoid modifying the original\n    df_normalized = df.copy()\n    \n    if exclude_columns is None:\n        exclude_columns = []\n    \n    # Select numeric columns, excluding specified columns\n    numeric_columns = df.select_dtypes(include=[np.number]).columns\n    columns_to_normalize = [col for col in numeric_columns if col not in exclude_columns]\n    \n    if method == 'minmax':\n        scaler = MinMaxScaler()\n    elif method == 'standard':\n        scaler = StandardScaler()\n    else:\n        raise ValueError(\"Method must be 'minmax' or 'standard'\")\n    \n    # Normalize each column independently\n    for column in columns_to_normalize:\n        df_normalized[column] = scaler.fit_transform(df_normalized[[column]])\n    \n    return df_normalized\n\n\n# Normalize using Standard scaling\ndf_train_minmax = normalize_dataframe_columns(filtered_df_train, method='standard')\ndf_test_minmax = normalize_dataframe_columns(df_test, method='standard')\n","metadata":{"execution":{"iopub.status.busy":"2024-09-06T22:43:49.543385Z","iopub.execute_input":"2024-09-06T22:43:49.543777Z","iopub.status.idle":"2024-09-06T22:43:49.969059Z","shell.execute_reply.started":"2024-09-06T22:43:49.543740Z","shell.execute_reply":"2024-09-06T22:43:49.968149Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"numeric_train_data = df_train_minmax.iloc[:, 1:].to_numpy()\nnumeric_test_data = df_test_minmax.iloc[:, 1:].to_numpy()","metadata":{"execution":{"iopub.status.busy":"2024-09-06T22:43:52.127273Z","iopub.execute_input":"2024-09-06T22:43:52.127712Z","iopub.status.idle":"2024-09-06T22:43:53.058058Z","shell.execute_reply.started":"2024-09-06T22:43:52.127676Z","shell.execute_reply":"2024-09-06T22:43:53.057236Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Combining image and tabular data","metadata":{}},{"cell_type":"code","source":"file_path_train = '/kaggle/input/isic-2024-challenge/train-image.hdf5'\nfile_path_test = '/kaggle/input/isic-2024-challenge/test-image.hdf5'\n\ndef hdf5_keys(image_dir):\n    with h5py.File(image_dir, 'r') as f:\n        # Get the name of the first dataset\n        dataset_names = list(f.keys())\n    return dataset_names\n\ntrain_keys = hdf5_keys(file_path_train)\ntest_keys = hdf5_keys(file_path_test)","metadata":{"execution":{"iopub.status.busy":"2024-09-06T22:43:55.078374Z","iopub.execute_input":"2024-09-06T22:43:55.078778Z","iopub.status.idle":"2024-09-06T22:44:55.601807Z","shell.execute_reply.started":"2024-09-06T22:43:55.078739Z","shell.execute_reply":"2024-09-06T22:44:55.600879Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# # Load and preprocess images\n\ndef load_images(image_dir, keys, numeric_df, batch, num_images=5000):\n    with h5py.File(image_dir, 'r') as f:\n        images = []\n        for idx, name in enumerate(keys[batch*num_images:(batch*num_images)+num_images]):\n            img = f[name][()]\n            img = Image.open(io.BytesIO(img))\n            img_resized = img.resize((128, 128))\n            img_array = np.asarray(img_resized).flatten() \n            df_row = numeric_df[batch*num_images + idx]\n            combined_array = np.concatenate([img_array, df_row]).astype(float)\n            images.append(combined_array)\n        return np.stack(images)\n\ntrain_img_stack = load_images(file_path_train, train_keys, numeric_train_data, 0)\ntest_img_stack = load_images(file_path_test, test_keys, numeric_test_data, 0, num_images=3)\n\nNsamples = len(train_img_stack)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-06T22:46:21.674094Z","iopub.execute_input":"2024-09-06T22:46:21.674853Z","iopub.status.idle":"2024-09-06T22:46:50.813747Z","shell.execute_reply.started":"2024-09-06T22:46:21.674810Z","shell.execute_reply":"2024-09-06T22:46:50.812711Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train_img_stack.shape\nnum_train = len(train_keys)\nbatch_size = 5000\ntotal_batches = (num_train + batch_size - 1) // (20*batch_size)\nprint(total_batches)","metadata":{"execution":{"iopub.status.busy":"2024-09-06T22:47:02.104351Z","iopub.execute_input":"2024-09-06T22:47:02.105093Z","iopub.status.idle":"2024-09-06T22:47:02.110573Z","shell.execute_reply.started":"2024-09-06T22:47:02.105045Z","shell.execute_reply":"2024-09-06T22:47:02.109583Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"4\n","output_type":"stream"}]},{"cell_type":"code","source":"from typing import Tuple\nfrom functools import partial\n\nclass BatchedMultiClassImageEnergyF(eqx.Module):\n    W_key: jax.Array  # Change this to a differentiable parameter\n    input_dim: int\n    num_memories: int\n    labelW: jax.Array\n    beta: float\n    \n    def __init__(self, input_dim: int, num_memories: int, num_classes: int, beta_init=1.):\n        key = jax.random.PRNGKey(0)\n        self.W_key = jax.random.uniform(key, (2,), dtype=jnp.float32)\n        self.input_dim = float(input_dim)  # Convert to float\n        self.num_memories = float(num_memories)  # Convert to float\n        self.labelW = jnp.zeros((num_memories, num_classes), dtype=jnp.float32)\n        self.beta = float(beta_init)  # Ensure beta is float\n\n    \n    def get_W(self, batch_size):\n        key = jax.random.PRNGKey(jnp.abs(self.W_key[0]).astype(jnp.uint32))\n        return jax.random.normal(key, (int(batch_size), int(self.input_dim)))\n    \n    def __call__(self, x: jax.Array, labels: jax.Array = None) -> jax.Array:\n        batch_size = x.shape[0]\n        W_batch = self.get_W(self.num_memories)\n        sim = -jnp.sum(jnp.square(W_batch[None, :, :] - x[:, None, :]), axis=-1)\n        energy = -self.beta * sim\n        return energy\n\n    def __hash__(self):\n        return hash((self.input_dim, self.num_memories, self.beta))\n\n\n@partial(jax.jit, static_argnums=(0,))\ndef batch_loss(model: BatchedMultiClassImageEnergyF, x: jax.Array) -> jax.Array:\n    energies = model(x)\n    return jnp.mean(energies)\n\n@partial(jax.jit, static_argnums=(0,))\ndef train_step(model: BatchedMultiClassImageEnergyF, x: jax.Array, learning_rate: float) -> Tuple[BatchedMultiClassImageEnergyF, float]:\n    def loss_fn(model):\n        energies = model(x)\n        return jnp.mean(energies)\n\n    loss, grads = jax.value_and_grad(loss_fn)(model)\n    model = eqx.apply_updates(model, jax.tree_map(lambda g: -learning_rate * g, grads))\n    return model, jax.lax.stop_gradient(loss)\n\n\ndef load_images(image_dir, keys, numeric_df, batch, num_images=1000):\n    with h5py.File(image_dir, 'r') as f:\n        images = []\n        for idx, name in enumerate(keys[batch*num_images:(batch*num_images)+num_images]):\n            img = f[name][()]\n            img = Image.open(io.BytesIO(img))\n            img_resized = img.resize((128, 128))\n            img_array = np.asarray(img_resized, dtype=np.float32).flatten() \n            df_row = numeric_df[batch*num_images + idx]\n            combined_array = np.concatenate([img_array, df_row]).astype(float)\n            images.append(combined_array)\n        return np.stack(images)\n\ndef train_model(file_path_train, train_keys, numeric_train_data, num_epochs, num_classes, learning_rate=1e-4):\n    num_train = len(train_keys)\n    batch_size = 1000\n    total_batches = (num_train + batch_size - 1) // (30*batch_size)\n    \n    # Load first batch to get input dimension\n    first_batch = load_images(file_path_train, train_keys, numeric_train_data, 0, num_images=1)\n    input_dim = first_batch.shape[1]\n    \n    # Initialize model\n    model = BatchedMultiClassImageEnergyF(input_dim, num_memories=1000, num_classes=num_classes, beta_init=10.0)\n    \n    for epoch in range(num_epochs):\n        epoch_start_time = time.time()\n        total_loss = 0.0\n        num_valid_batches = 0\n        \n        for batch in range(total_batches):\n            batch_data = load_images(file_path_train, train_keys, numeric_train_data, batch)\n            batch_data = jnp.array(batch_data, dtype=jnp.float32)\n            \n            model, loss = train_step(model, batch_data, learning_rate)\n            \n            if jnp.isfinite(loss):\n                total_loss += loss\n                num_valid_batches += 1\n            else:\n                print(f\"Non-finite loss encountered in batch {batch}. Skipping.\")\n            \n            del batch_data\n            jax.clear_caches()\n        \n        epoch_end_time = time.time()\n        epoch_time = epoch_end_time - epoch_start_time\n        \n        if num_valid_batches > 0:\n            avg_loss = total_loss / num_valid_batches\n            print(f\"Epoch {epoch+1}, Average Loss: {avg_loss:.4f}, Time: {epoch_time:.2f} seconds\")\n        else:\n            print(f\"Epoch {epoch+1}, All batches produced non-finite losses. Consider adjusting hyperparameters.\")\n    \n    return model\n\n\n# Usage\nnum_epochs = 10\nnum_classes = 5000\nlearning_rate = 1e-4\n\ntrained_model = train_model(file_path_train, train_keys, numeric_train_data, num_epochs, num_classes, learning_rate)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-09-06T23:00:44.554266Z","iopub.execute_input":"2024-09-06T23:00:44.554707Z","iopub.status.idle":"2024-09-06T23:00:56.785850Z","shell.execute_reply.started":"2024-09-06T23:00:44.554665Z","shell.execute_reply":"2024-09-06T23:00:56.784472Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_36/1904958969.py:47: DeprecationWarning: jax.tree_map is deprecated: use jax.tree.map (jax v0.4.25 or newer) or jax.tree_util.tree_map (any JAX version).\n  model = eqx.apply_updates(model, jax.tree_map(lambda g: -learning_rate * g, grads))\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[19], line 113\u001b[0m\n\u001b[1;32m    110\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5000\u001b[39m\n\u001b[1;32m    111\u001b[0m learning_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-4\u001b[39m\n\u001b[0;32m--> 113\u001b[0m trained_model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_train_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[19], line 85\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(file_path_train, train_keys, numeric_train_data, num_epochs, num_classes, learning_rate)\u001b[0m\n\u001b[1;32m     82\u001b[0m batch_data \u001b[38;5;241m=\u001b[39m load_images(file_path_train, train_keys, numeric_train_data, batch)\n\u001b[1;32m     83\u001b[0m batch_data \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39marray(batch_data, dtype\u001b[38;5;241m=\u001b[39mjnp\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m---> 85\u001b[0m model, loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m jnp\u001b[38;5;241m.\u001b[39misfinite(loss):\n\u001b[1;32m     88\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n","\u001b[0;31mValueError\u001b[0m: Non-hashable static arguments are not supported. An error occurred while trying to hash an object of type <class '__main__.BatchedMultiClassImageEnergyF'>, BatchedMultiClassImageEnergyF(\n  W_key=f32[2],\n  input_dim=f32[],\n  num_memories=f32[],\n  labelW=f32[1000,5000],\n  beta=f32[]\n). The error was:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n  File \"/opt/conda/lib/python3.10/runpy.py\", line 86, in _run_code\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n  File \"/opt/conda/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n  File \"/opt/conda/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n  File \"/opt/conda/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n  File \"/opt/conda/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n  File \"/opt/conda/lib/python3.10/asyncio/events.py\", line 80, in _run\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3106, in _run_cell\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3311, in run_cell_async\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3493, in run_ast_nodes\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n  File \"/tmp/ipykernel_36/1904958969.py\", line 113, in <module>\n  File \"/tmp/ipykernel_36/1904958969.py\", line 85, in train_model\n  File \"/tmp/ipykernel_36/1904958969.py\", line 32, in __hash__\nTypeError: unhashable type: 'jaxlib.xla_extension.DeviceList'\n"],"ename":"ValueError","evalue":"Non-hashable static arguments are not supported. An error occurred while trying to hash an object of type <class '__main__.BatchedMultiClassImageEnergyF'>, BatchedMultiClassImageEnergyF(\n  W_key=f32[2],\n  input_dim=f32[],\n  num_memories=f32[],\n  labelW=f32[1000,5000],\n  beta=f32[]\n). The error was:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n  File \"/opt/conda/lib/python3.10/runpy.py\", line 86, in _run_code\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n  File \"/opt/conda/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n  File \"/opt/conda/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n  File \"/opt/conda/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n  File \"/opt/conda/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n  File \"/opt/conda/lib/python3.10/asyncio/events.py\", line 80, in _run\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3106, in _run_cell\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3311, in run_cell_async\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3493, in run_ast_nodes\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n  File \"/tmp/ipykernel_36/1904958969.py\", line 113, in <module>\n  File \"/tmp/ipykernel_36/1904958969.py\", line 85, in train_model\n  File \"/tmp/ipykernel_36/1904958969.py\", line 32, in __hash__\nTypeError: unhashable type: 'jaxlib.xla_extension.DeviceList'\n","output_type":"error"}]},{"cell_type":"code","source":"# Example of using batch_find_most_similar_image (defined separately to save memory)\n@jax.jit\ndef batch_find_most_similar_image(model: BatchedMultiClassImageEnergyF, test_images: jax.Array) -> Tuple[jax.Array, jax.Array]:\n    energies = model(test_images)\n    most_similar_idx = jnp.argmin(energies, axis=-1)\n    return most_similar_idx, energies\n\n# Load and process a small batch of test images\ntest_images = load_images(file_path_train, train_keys, numeric_train_data, 0, num_images=10)\ntest_images = jax.device_put(test_images)\nmost_similar_idx, energies = batch_find_most_similar_image(trained_model, test_images)\n\nfor i in range(len(most_similar_idx)):\n    print(f\"Test image {i}:\")\n    print(f\"  Most similar image index: {most_similar_idx[i]}\")\n    print(f\"  Energy: {energies[i, most_similar_idx[i]]}\")\n    print()\n\n# Example of using batch_find_most_similar_image\ntest_images = train_img_stack[5:10]  # Using first 5 training images as test for demonstration\nmost_similar_idx, energies = batch_find_most_similar_image(trained_model, test_images)\n\nfor i in range(len(most_similar_idx)):\n    print(f\"Test image {i}:\")\n    print(f\"  Most similar image index: {most_similar_idx[i]}\")\n    print(f\"  Energy: {energies[i, most_similar_idx[i]]}\")\n    print()","metadata":{"execution":{"iopub.status.busy":"2024-09-06T22:09:45.411095Z","iopub.execute_input":"2024-09-06T22:09:45.411503Z","iopub.status.idle":"2024-09-06T22:09:45.445571Z","shell.execute_reply.started":"2024-09-06T22:09:45.411466Z","shell.execute_reply":"2024-09-06T22:09:45.444606Z"},"trusted":true},"execution_count":110,"outputs":[{"name":"stdout","text":"Test image 0:\n  Most similar image index: 5\n  Energy: 9.704568862915039\n\nTest image 1:\n  Most similar image index: 6\n  Energy: 8.085163116455078\n\nTest image 2:\n  Most similar image index: 7\n  Energy: 9.575321197509766\n\nTest image 3:\n  Most similar image index: 8\n  Energy: 5.613557815551758\n\nTest image 4:\n  Most similar image index: 9\n  Energy: 12.148567199707031\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# def to_vectors(x):\n#     return rearrange(x, \"... h w c -> ... (h w c)\") / 255.\n\n# train_img_stack[:3].shape\n# question = train_img_stack[:3].flatten()\n# print(train_img_stack[:3][0].shape, question.shape)\n# test = to_vectors(train_img_stack[:3])\n# print(test.shape, question.shape)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-06T21:39:03.725448Z","iopub.execute_input":"2024-09-06T21:39:03.726393Z","iopub.status.idle":"2024-09-06T21:39:03.731075Z","shell.execute_reply.started":"2024-09-06T21:39:03.726324Z","shell.execute_reply":"2024-09-06T21:39:03.730060Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"# def to_vectors(x):\n#     return rearrange(x, \"... h w c -> ... (h w c)\") / 255.\n\n\n# class MultiClassImageEnergyF(eqx.Module):\n#     W: jax.Array\n#     labelW: jax.Array\n#     beta: float\n    \n#     def __init__(self, Winit: jax.Array, labelW_init: jax.Array, beta_init=1.):\n#         self.W = jnp.array(Winit)\n#         self.labelW = jnp.array(labelW_init)\n#         self.beta = beta_init\n        \n#     def __call__(self, x, labels=None):\n#         \"\"\"Compute the energy of the memories given a particular label\"\"\"\n#         assert len(x.shape) < 2, \"No batch dimension\"\n\n#         sim = -jnp.sum(jnp.power(self.W - x, 2), -1)\n        \n#         if labels is not None:\n#             simlabel = self.labelW @ labels\n#             energy = -jax.nn.logsumexp(self.beta * (sim + simlabel))\n#         else:\n#             energy = -jax.nn.logsumexp(self.beta * sim[:, None] + self.labelW.T, axis=1)\n#         return energy\n\n# def find_most_similar_image(model, test_image):\n#     energies = model(test_image)\n#     most_similar_idx = jnp.argmin(energies)\n#     return most_similar_idx, energies\n\n# def display_images(test_image, most_similar_image, most_similar_idx):\n#     fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n    \n#     ax1.imshow(test_image)\n#     ax1.set_title(\"Test Image\")\n#     ax1.axis('off')\n    \n#     ax2.imshow(most_similar_image)\n#     ax2.set_title(f\"Most Similar Idx\\n{most_similar_idx}\")\n#     ax2.axis('off')\n    \n#     plt.tight_layout()\n#     plt.show()    ","metadata":{"execution":{"iopub.status.busy":"2024-09-06T20:10:06.831551Z","iopub.execute_input":"2024-09-06T20:10:06.832301Z","iopub.status.idle":"2024-09-06T20:10:06.838469Z","shell.execute_reply.started":"2024-09-06T20:10:06.832258Z","shell.execute_reply":"2024-09-06T20:10:06.837486Z"},"trusted":true},"execution_count":119,"outputs":[]},{"cell_type":"code","source":"# W = to_vectors(train_img_stack)\n# labels = jnp.arange(Nsamples)\n# labelW = jax.nn.one_hot(jnp.arange(Nsamples), num_classes=Nsamples)\n    \n\n# # Initialize the model\n# num_classes = 2\n# model = MultiClassImageEnergyF(W, num_classes, beta_init=10.)","metadata":{"execution":{"iopub.status.busy":"2024-09-06T16:26:48.849227Z","iopub.execute_input":"2024-09-06T16:26:48.850135Z","iopub.status.idle":"2024-09-06T16:26:48.853703Z","shell.execute_reply.started":"2024-09-06T16:26:48.850096Z","shell.execute_reply":"2024-09-06T16:26:48.852797Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"# import matplotlib.pyplot as plt\n\n# def plot_energy_scatter(energies, title=\"Energy Scatter Plot\", x_label=\"Data Point\", y_label=\"Energy\"):\n#     \"\"\"\n#     Plot a scatter plot of energies against the number of data points.\n    \n#     Parameters:\n#     energies (list): List of energy values to plot\n#     title (str): Title of the plot\n#     x_label (str): Label for the x-axis\n#     y_label (str): Label for the y-axis\n#     \"\"\"\n#     # Generate x-axis values (1 to number of data points)\n#     x_values = range(1, len(energies) + 1)\n    \n#     # Create the scatter plot\n#     plt.figure(figsize=(10, 6))\n#     plt.scatter(x_values, energies, alpha=0.2)\n    \n#     # Set title and labels\n#     plt.title(title)\n#     plt.xlabel(x_label)\n#     plt.ylabel(y_label)\n    \n#     # Set y-axis limits\n#     plt.ylim(-200000, -190000)\n    \n#     # Add grid for better readability\n#     plt.grid(True, linestyle='--', alpha=0.7)\n    \n#     # Show the plot\n#     plt.show()\n\n# # Example usage\n# # Uncomment and modify these lines to test the function\n# # import numpy as np\n# # sample_energies = np.random.rand(100) * 10  # 100 random energy values between 0 and 10\n# # plot_energy_scatter(sample_energies, title=\"Sample Energy Distribution\")","metadata":{"execution":{"iopub.status.busy":"2024-09-06T16:26:59.248119Z","iopub.execute_input":"2024-09-06T16:26:59.248489Z","iopub.status.idle":"2024-09-06T16:26:59.252859Z","shell.execute_reply.started":"2024-09-06T16:26:59.248460Z","shell.execute_reply":"2024-09-06T16:26:59.251995Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"# import jax\n# import jax.numpy as jnp\n# import equinox as eqx\n# from typing import Tuple, Callable\n# import time\n\n# class BatchedMultiClassImageEnergyF(eqx.Module):\n#     W: jax.Array\n#     labelW: jax.Array\n#     beta: float\n    \n#     def __init__(self, Winit: jax.Array, num_classes: int, beta_init=1.):\n#         self.W = jnp.array(Winit) \n#         num_memories = Winit.shape[0]\n#         self.labelW = jnp.zeros((num_memories, num_classes))\n#         self.beta = beta_init\n        \n#     def __call__(self, x: jax.Array, labels: jax.Array = None) -> jax.Array:\n#         \"\"\"Compute the energy of the memories given a particular label for a batch of inputs\"\"\"\n#         # Compute similarity: shape will be (batch_size, num_memories)\n#         sim = -jnp.sum(jnp.square(self.W[None, :, :] - x[:, None, :]), axis=-1)\n#         energy = -self.beta * sim\n        \n#         return energy\n\n# @eqx.filter_value_and_grad\n# def batch_loss(model: BatchedMultiClassImageEnergyF, x: jax.Array) -> jax.Array:\n#     energies = model(x)\n#     return jnp.mean(energies)\n\n# @eqx.filter_jit\n# def train_step(model: BatchedMultiClassImageEnergyF, x: jax.Array, \n#                optimizer_update: Callable) -> Tuple[BatchedMultiClassImageEnergyF, float]:\n#     loss, grads = batch_loss(model, x)\n#     updates = jax.tree.map(lambda g: -0.001 * g, grads)\n#     model = eqx.apply_updates(model, updates)\n#     return model, loss\n\n# @eqx.filter_jit\n# def batch_find_most_similar_image(model: BatchedMultiClassImageEnergyF, test_images: jax.Array) -> Tuple[jax.Array, jax.Array]:\n#     energies = model(test_images)  # Shape: (num_test_images, num_memories)\n#     most_similar_idx = jnp.argmin(energies, axis=-1)\n#     return most_similar_idx, energies\n\n\n# num_memories = 5000\n# num_classes = 100\n# batch_size = 128\n# num_epochs = 1\n# num_train = 1000\n\n# num_images = len(train_keys) / 70\n# batches = int(num_images // num_train)\n# print(batches, num_images, int(num_images - batches*num_train))\n","metadata":{"execution":{"iopub.status.busy":"2024-09-06T21:44:29.504640Z","iopub.execute_input":"2024-09-06T21:44:29.505709Z","iopub.status.idle":"2024-09-06T21:44:29.526508Z","shell.execute_reply.started":"2024-09-06T21:44:29.505663Z","shell.execute_reply":"2024-09-06T21:44:29.525354Z"},"trusted":true},"execution_count":75,"outputs":[{"name":"stdout","text":"5 5729.414285714286 729\n","output_type":"stream"}]},{"cell_type":"code","source":"df_sub = pd.read_csv(\"/kaggle/input/isic-2024-challenge/sample_submission.csv\")\ndf_sub[\"target\"] = preds\ndf_sub.to_csv(\"submission.csv\", index=False)\ndf_sub","metadata":{"execution":{"iopub.status.busy":"2024-08-16T06:25:59.643276Z","iopub.execute_input":"2024-08-16T06:25:59.64367Z","iopub.status.idle":"2024-08-16T06:25:59.701154Z","shell.execute_reply.started":"2024-08-16T06:25:59.643636Z","shell.execute_reply":"2024-08-16T06:25:59.699236Z"},"trusted":true},"execution_count":null,"outputs":[]}]}