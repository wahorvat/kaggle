{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":63056,"databundleVersionId":9094797,"sourceType":"competition"}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport pandas.api.types\nimport jax\nimport jax.numpy as jnp\nfrom jax import jit\nfrom flax import linen as nn\n\nimport h5py\nimport itertools\nfrom PIL import Image\nfrom pathlib import Path\nimport time\n\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\n\nfrom scipy.stats import zscore\nfrom numpy import nanmean, nanstd\nnp.seterr(invalid='ignore')\n\nimport copy\nimport os\nimport io","metadata":{"execution":{"iopub.status.busy":"2024-09-11T00:09:03.567416Z","iopub.execute_input":"2024-09-11T00:09:03.568520Z","iopub.status.idle":"2024-09-11T00:09:03.577350Z","shell.execute_reply.started":"2024-09-11T00:09:03.568465Z","shell.execute_reply":"2024-09-11T00:09:03.576234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file_path_train_meta = '/kaggle/input/isic-2024-challenge/train-metadata.csv'\nfile_path_test_meta = '/kaggle/input/isic-2024-challenge/test-metadata.csv'\n\ndf_train = pd.read_csv(file_path_train_meta)\ndf_test = pd.read_csv(file_path_test_meta)","metadata":{"execution":{"iopub.status.busy":"2024-09-11T00:09:06.794987Z","iopub.execute_input":"2024-09-11T00:09:06.795360Z","iopub.status.idle":"2024-09-11T00:09:14.154789Z","shell.execute_reply.started":"2024-09-11T00:09:06.795326Z","shell.execute_reply":"2024-09-11T00:09:14.153799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_targets = df_train['target'].to_numpy()\n\n# unique, counts = np.unique(train_targets, return_counts=True)\n# count_dict = dict(zip(unique, counts))\n# print(count_dict, train_targets.shape)","metadata":{"execution":{"iopub.status.busy":"2024-09-11T00:09:29.457045Z","iopub.execute_input":"2024-09-11T00:09:29.457725Z","iopub.status.idle":"2024-09-11T00:09:29.461962Z","shell.execute_reply.started":"2024-09-11T00:09:29.457684Z","shell.execute_reply":"2024-09-11T00:09:29.460926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def filter_columns(df: pd.DataFrame, keep_columns: list) -> pd.DataFrame:\n    \"\"\"\n    Remove columns from a DataFrame that are not in the specified list.\n    \n    :param df: Input DataFrame\n    :param keep_columns: List of column names to keep\n    :return: DataFrame with only the specified columns\n    \"\"\"\n    # Find the intersection of existing columns and the keep_columns list\n    columns_to_keep = [col for col in keep_columns if col in df.columns]\n    \n    # Return the DataFrame with only the specified columns\n    return df[columns_to_keep]\n\ntest_cols = df_test.columns\nprint(test_cols)\n\nfiltered_df_train = filter_columns(df_train, test_cols)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-11T00:09:31.721541Z","iopub.execute_input":"2024-09-11T00:09:31.722385Z","iopub.status.idle":"2024-09-11T00:09:31.786269Z","shell.execute_reply.started":"2024-09-11T00:09:31.722339Z","shell.execute_reply":"2024-09-11T00:09:31.785393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_cols = ['patient_id','age_approx', 'sex', 'anatom_site_general', \n            'image_type', 'tbp_tile_type', 'tbp_lv_location', \n            'tbp_lv_location_simple', 'attribution', 'copyright_license']","metadata":{"execution":{"iopub.status.busy":"2024-09-11T00:09:34.821049Z","iopub.execute_input":"2024-09-11T00:09:34.821910Z","iopub.status.idle":"2024-09-11T00:09:34.826031Z","shell.execute_reply.started":"2024-09-11T00:09:34.821867Z","shell.execute_reply":"2024-09-11T00:09:34.825095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filtered_df_train = filtered_df_train.copy()\n\n# Encode categories\ncategory_encoder = OrdinalEncoder(\n    categories='auto',\n    dtype=int,\n    handle_unknown='use_encoded_value',\n    unknown_value=-2,\n    encoded_missing_value=-1,\n)\n\n# Transform training data\nX_cat_train = category_encoder.fit_transform(filtered_df_train[cat_cols])\nfor c, cat_col in enumerate(cat_cols):\n    filtered_df_train.loc[:, cat_col] = X_cat_train[:, c]\n\n# Transform test data\nX_cat_test = category_encoder.transform(df_test[cat_cols])\nfor c, cat_col in enumerate(cat_cols):\n    df_test.loc[:, cat_col] = X_cat_test[:, c]\n\nprint(\"Encoding complete.\")","metadata":{"execution":{"iopub.status.busy":"2024-09-11T00:09:37.377979Z","iopub.execute_input":"2024-09-11T00:09:37.378932Z","iopub.status.idle":"2024-09-11T00:09:38.709724Z","shell.execute_reply.started":"2024-09-11T00:09:37.378883Z","shell.execute_reply":"2024-09-11T00:09:38.708770Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def normalize_dataframe_columns(df, method='minmax', exclude_columns=None):\n    \"\"\"\n    Normalize each column of a DataFrame independently.\n    \n    :param df: Input DataFrame\n    :param method: 'minmax' for Min-Max scaling, 'standard' for Standardization\n    :param exclude_columns: List of column names to exclude from normalization\n    :return: Normalized DataFrame\n    \"\"\"\n    # Create a copy of the DataFrame to avoid modifying the original\n    df_normalized = df.copy()\n    \n    if exclude_columns is None:\n        exclude_columns = []\n    \n    # Select numeric columns, excluding specified columns\n    numeric_columns = df.select_dtypes(include=[np.number]).columns\n    columns_to_normalize = [col for col in numeric_columns if col not in exclude_columns]\n    \n    if method == 'minmax':\n        scaler = MinMaxScaler()\n    elif method == 'standard':\n        scaler = StandardScaler()\n    else:\n        raise ValueError(\"Method must be 'minmax' or 'standard'\")\n    \n    # Normalize each column independently\n    for column in columns_to_normalize:\n        df_normalized[column] = scaler.fit_transform(df_normalized[[column]])\n    \n    return df_normalized\n\n\n# Normalize using Standard scaling\ndf_train_minmax = normalize_dataframe_columns(filtered_df_train, method='standard')\ndf_test_minmax = normalize_dataframe_columns(df_test, method='standard')\n","metadata":{"execution":{"iopub.status.busy":"2024-09-11T00:09:41.217368Z","iopub.execute_input":"2024-09-11T00:09:41.217782Z","iopub.status.idle":"2024-09-11T00:09:41.621978Z","shell.execute_reply.started":"2024-09-11T00:09:41.217714Z","shell.execute_reply":"2024-09-11T00:09:41.621008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert df row data to row elements in a jax array of type float\nnumeric_train_data_jax = jnp.array(df_train_minmax.iloc[0:, 1:].to_numpy(dtype=float))\nnumeric_test_data_jax = jnp.array(df_test_minmax.iloc[0:, 1:].to_numpy(dtype=float))","metadata":{"execution":{"iopub.status.busy":"2024-09-11T00:09:44.896630Z","iopub.execute_input":"2024-09-11T00:09:44.897043Z","iopub.status.idle":"2024-09-11T00:09:46.670279Z","shell.execute_reply.started":"2024-09-11T00:09:44.897001Z","shell.execute_reply":"2024-09-11T00:09:46.669232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Combining image and tabular data","metadata":{}},{"cell_type":"code","source":"file_path_train = '/kaggle/input/isic-2024-challenge/train-image.hdf5'\nfile_path_test = '/kaggle/input/isic-2024-challenge/test-image.hdf5'\n\ndef hdf5_keys(image_dir):\n    with h5py.File(image_dir, 'r') as f:\n        dataset_names = list(f.keys())\n    return dataset_names\n\ntrain_keys = hdf5_keys(file_path_train)\ntest_keys = hdf5_keys(file_path_test)","metadata":{"execution":{"iopub.status.busy":"2024-09-11T00:09:49.146283Z","iopub.execute_input":"2024-09-11T00:09:49.147172Z","iopub.status.idle":"2024-09-11T00:10:53.915519Z","shell.execute_reply.started":"2024-09-11T00:09:49.147130Z","shell.execute_reply":"2024-09-11T00:10:53.914583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Load and preprocess images\n\ndef load_images(image_dir, keys, numeric_df, batch, num_images=5000):\n    with h5py.File(image_dir, 'r') as f:\n        images = []\n        for idx, name in enumerate(keys[batch*num_images:(batch*num_images)+num_images]):\n            img = f[name][()]\n            img = Image.open(io.BytesIO(img))\n            img_resized = img.resize((128, 128))\n            img_array = jnp.asarray(img_resized).flatten() \n            df_row = numeric_df[batch*num_images + idx]\n            combined_array = jnp.concatenate([img_array, df_row])\n            images.append(combined_array)\n        return jnp.stack(images)\n\n\n# train_img_stack = load_images(file_path_train, train_keys, numeric_train_data_jax, 0)\n# test_img_stack = load_images(file_path_test, test_keys, numeric_test_data_jax, 0, num_images=3)","metadata":{"execution":{"iopub.status.busy":"2024-09-11T00:11:57.116095Z","iopub.execute_input":"2024-09-11T00:11:57.116489Z","iopub.status.idle":"2024-09-11T00:11:57.123829Z","shell.execute_reply.started":"2024-09-11T00:11:57.116452Z","shell.execute_reply":"2024-09-11T00:11:57.122890Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# JAX only model\ndef create_model(Winit: jax.Array, labelW_init: jax.Array, beta_init=1.):\n    return {\n        'W': jnp.array(Winit),\n        'labelW': jnp.array(labelW_init),\n        'beta': beta_init\n    }\n\ndef model_call(params, x):\n    \"\"\"Compute the energy of the memories given a particular label\"\"\"\n    assert len(x.shape) < 2, \"No batch dimension\"\n    sim = -jnp.sum(jnp.power(params['W'] - x, 2), -1)    \n    energy = -jax.nn.logsumexp(params['beta'] * sim[:, None] + params['labelW'].T, axis=1)\n    return energy\n\ndef update_model(params, new_W: jax.Array, new_labelW: jax.Array):\n    \"\"\"Update the model with new data\"\"\"\n    return {\n        'W': new_W,\n        'labelW': new_labelW,\n        'beta': params['beta']\n    }\n\n\ndef find_similar_samples_with_prob(params, test_images, train_targets):\n    # Vectorize the model call over the batch dimension\n    batched_model = jax.vmap(lambda x: model_call(params, x))\n    \n    # Compute energies for all test images in parallel\n    energies = batched_model(test_images)\n\n    output = []\n    \n    # Normalize energies to range [0, 1]\n    for energy_list in energies:\n        max_energy = jnp.max(energy_list)\n        min_energy = jnp.min(energy_list)\n        normalized_energy = jnp.sort((energy_list - min_energy) / (max_energy - min_energy))[:20]\n\n        # Convert normalized energies to probabilities\n        # Lower energy means higher similarity, so we negate the energies\n        similarities = jnp.exp(-normalized_energy)\n        \n        # Normalize similarities to get probabilities\n        probability = jnp.max(similarities / jnp.sum(similarities, axis=0, keepdims=True))    \n        most_similar_idx = jnp.argmin(energy_list)\n        \n        output.append(list(zip([probability], [most_similar_idx])))\n\n    return output\n\n\n# Ensure the function runs on GPU\n@jax.jit\ndef jitted_find_similar_samples_with_prob(params, test_images, train_targets):\n    return find_similar_samples_with_prob(params, test_images, train_targets)\n\n# def find_most_similar_image(params, test_images):\n#     # Vectorize the model call over the batch dimension\n#     batched_model = jax.vmap(lambda x: model_call(params, x))\n    \n#     # Compute energies for all test images in parallel\n#     energies = batched_model(test_images)\n    \n#     # Find the most similar index for each test image\n#     most_similar_idxs = jnp.argmin(energies, axis=1)\n    \n#     return most_similar_idxs\n\n# # Ensure the function runs on GPU\n# @jax.jit\n# def jitted_find_most_similar_image(params, test_images):\n#     return find_most_similar_image(params, test_images)","metadata":{"execution":{"iopub.status.busy":"2024-09-11T00:27:21.448714Z","iopub.execute_input":"2024-09-11T00:27:21.449134Z","iopub.status.idle":"2024-09-11T00:27:21.461688Z","shell.execute_reply.started":"2024-09-11T00:27:21.449098Z","shell.execute_reply":"2024-09-11T00:27:21.460674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_train = len(train_keys)\nnum_test = len(test_keys)\n\nbatch_size = 5000\ntotal_train_batches = (num_train + batch_size - 1) // batch_size\ntotal_test_batches = (num_test + batch_size - 1) // batch_size\nprint(total_test_batches)","metadata":{"execution":{"iopub.status.busy":"2024-09-11T00:34:31.738513Z","iopub.execute_input":"2024-09-11T00:34:31.739201Z","iopub.status.idle":"2024-09-11T00:34:31.745126Z","shell.execute_reply.started":"2024-09-11T00:34:31.739159Z","shell.execute_reply":"2024-09-11T00:34:31.744124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize model\nnum_classes = 20000\ntrain_img_stack = load_images(file_path_train, train_keys, numeric_train_data_jax, batch=0)\n\nW_init = train_img_stack[0:batch_size]\nlabelW_init = jax.nn.one_hot(jnp.arange(batch_size), num_classes=batch_size)\nmodel_params = create_model(W_init, labelW_init, beta_init=1.)\n\n\n# Training loop on training images and numeric data, loss and epochs are irrelevant to model training\nfor train_batch in range(1, total_train_batches):\n    start_time = time.time()\n    train_img_stack = load_images(file_path_train, train_keys, numeric_train_data_jax, train_batch)\n    W = train_img_stack\n    Nsamples = len(W)\n    \n    labels = jnp.arange(Nsamples)\n    labelW = jax.nn.one_hot(jnp.arange(Nsamples), num_classes=Nsamples)\n\n    # Update the existing model with new data\n    model_params = update_model(model_params, W, labelW)\n\n    if train_batch % 10 == 0:\n        end_time = time.time()\n        print(f'Time for batches {train_batch-10} through {train_batch} of {total_train_batches} is {end_time - start_time}')\n","metadata":{"execution":{"iopub.status.busy":"2024-09-11T00:12:16.966264Z","iopub.execute_input":"2024-09-11T00:12:16.966649Z","iopub.status.idle":"2024-09-11T00:12:55.035612Z","shell.execute_reply.started":"2024-09-11T00:12:16.966613Z","shell.execute_reply":"2024-09-11T00:12:55.034579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = np.zeros(len(test_keys))\n\nfor test_batch in range(total_test_batches):    \n    test_img_stack = load_images(file_path_test, test_keys, numeric_test_data_jax, test_batch)\n    num_imgs = len(test_img_stack)\n    outputs = jitted_find_similar_samples_with_prob(model_params, test_img_stack, train_targets)\n    for pred_idx, prob_sim_idx in enumerate(outputs):\n        if train_targets[prob_sim_idx[0][1]] == 0:\n            preds[(test_batch*num_imgs)+pred_idx] = prob_sim_idx[0][0]\n        else:\n            preds[(test_batch*num_imgs)+pred_idx] = 1 - prob_sim_idx[0][0]","metadata":{"execution":{"iopub.status.busy":"2024-09-11T00:32:09.751487Z","iopub.execute_input":"2024-09-11T00:32:09.751897Z","iopub.status.idle":"2024-09-11T00:32:09.782996Z","shell.execute_reply.started":"2024-09-11T00:32:09.751860Z","shell.execute_reply":"2024-09-11T00:32:09.782222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_sub = pd.read_csv(\"/kaggle/input/isic-2024-challenge/sample_submission.csv\")\ndf_sub[\"target\"] = preds\ndf_sub.to_csv(\"submission.csv\", index=False)\ndf_sub","metadata":{"execution":{"iopub.status.busy":"2024-09-10T15:14:59.095065Z","iopub.execute_input":"2024-09-10T15:14:59.095392Z","iopub.status.idle":"2024-09-10T15:14:59.100555Z","shell.execute_reply.started":"2024-09-10T15:14:59.095356Z","shell.execute_reply":"2024-09-10T15:14:59.099463Z"},"trusted":true},"execution_count":null,"outputs":[]}]}